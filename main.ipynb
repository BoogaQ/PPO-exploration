{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from models import *\n",
    "from ppo import PPO, PPO_RND, PPO_ICM\n",
    "from buffer import RolloutStorage\n",
    "from env import *\n",
    "\n",
    "import torch\n",
    "import torch.distributions as distributions\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "from stable_baselines3.common.cmd_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import vec_normalize, SubprocVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybulletgym\n",
    "env = make_vec_env(\"LunarLanderContinuous-v2\", 4, vec_env_cls = SubprocVecEnv)\n",
    "env = VecNormalize(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -629     |\n",
      "|    num_episodes         | 11       |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 1280     |\n",
      "|    total_time           | 0.786    |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00518 |\n",
      "|    total_loss           | 0.0527   |\n",
      "|    value_loss           | 0.0721   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -551     |\n",
      "|    num_episodes         | 21       |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 2560     |\n",
      "|    total_time           | 1.59     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00623 |\n",
      "|    total_loss           | 0.0105   |\n",
      "|    value_loss           | 0.0309   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -480     |\n",
      "|    num_episodes         | 34       |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 3840     |\n",
      "|    total_time           | 2.38     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00385 |\n",
      "|    total_loss           | 0.0202   |\n",
      "|    value_loss           | 0.0383   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_rew_mean          | -439      |\n",
      "|    num_episodes         | 47        |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 5120      |\n",
      "|    total_time           | 3.29      |\n",
      "| train/                  |           |\n",
      "|    entropy_loss         | -1.42     |\n",
      "|    policy_gradient_loss | -0.000254 |\n",
      "|    total_loss           | 0.0155    |\n",
      "|    value_loss           | 0.03      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -402     |\n",
      "|    num_episodes         | 61       |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 6400     |\n",
      "|    total_time           | 4.15     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.0037  |\n",
      "|    total_loss           | 0.0173   |\n",
      "|    value_loss           | 0.0352   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -382     |\n",
      "|    num_episodes         | 75       |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 7680     |\n",
      "|    total_time           | 4.99     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00402 |\n",
      "|    total_loss           | 0.00785  |\n",
      "|    value_loss           | 0.0261   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -353     |\n",
      "|    num_episodes         | 89       |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 8960     |\n",
      "|    total_time           | 5.78     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.0023  |\n",
      "|    total_loss           | 0.0244   |\n",
      "|    value_loss           | 0.0409   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -321     |\n",
      "|    num_episodes         | 104      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 10240    |\n",
      "|    total_time           | 6.56     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.0061  |\n",
      "|    total_loss           | 0.00673  |\n",
      "|    value_loss           | 0.027    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -263     |\n",
      "|    num_episodes         | 117      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 11520    |\n",
      "|    total_time           | 7.34     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00147  |\n",
      "|    total_loss           | 2.18e-05 |\n",
      "|    value_loss           | 0.0127   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -232     |\n",
      "|    num_episodes         | 126      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 12800    |\n",
      "|    total_time           | 8.21     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00116 |\n",
      "|    total_loss           | 0.051    |\n",
      "|    value_loss           | 0.0664   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -202     |\n",
      "|    num_episodes         | 138      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 14080    |\n",
      "|    total_time           | 9.1      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00364  |\n",
      "|    total_loss           | 0.00721  |\n",
      "|    value_loss           | 0.0178   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -180     |\n",
      "|    num_episodes         | 148      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 15360    |\n",
      "|    total_time           | 10       |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00321 |\n",
      "|    total_loss           | -0.0109  |\n",
      "|    value_loss           | 0.00654  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -164     |\n",
      "|    num_episodes         | 159      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 16640    |\n",
      "|    total_time           | 10.9     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00752 |\n",
      "|    total_loss           | -0.0138  |\n",
      "|    value_loss           | 0.00789  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -157     |\n",
      "|    num_episodes         | 169      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 17920    |\n",
      "|    total_time           | 11.8     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00258 |\n",
      "|    total_loss           | -0.00447 |\n",
      "|    value_loss           | 0.0123   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -145     |\n",
      "|    num_episodes         | 175      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 19200    |\n",
      "|    total_time           | 12.8     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00269 |\n",
      "|    total_loss           | -0.0017  |\n",
      "|    value_loss           | 0.0152   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -146     |\n",
      "|    num_episodes         | 182      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 20480    |\n",
      "|    total_time           | 13.7     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00227 |\n",
      "|    total_loss           | -0.00902 |\n",
      "|    value_loss           | 0.00744  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -147     |\n",
      "|    num_episodes         | 189      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 21760    |\n",
      "|    total_time           | 14.6     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.0029  |\n",
      "|    total_loss           | 0.0738   |\n",
      "|    value_loss           | 0.0909   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -137     |\n",
      "|    num_episodes         | 199      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 23040    |\n",
      "|    total_time           | 15.5     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00135 |\n",
      "|    total_loss           | -0.00122 |\n",
      "|    value_loss           | 0.0143   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -132     |\n",
      "|    num_episodes         | 208      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 24320    |\n",
      "|    total_time           | 16.5     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00799 |\n",
      "|    total_loss           | 0.00908  |\n",
      "|    value_loss           | 0.0313   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -125     |\n",
      "|    num_episodes         | 212      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 25600    |\n",
      "|    total_time           | 17.5     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00131  |\n",
      "|    total_loss           | -0.00423 |\n",
      "|    value_loss           | 0.00865  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -125     |\n",
      "|    num_episodes         | 215      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 26880    |\n",
      "|    total_time           | 18.8     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00423 |\n",
      "|    total_loss           | -0.00476 |\n",
      "|    value_loss           | 0.0137   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -124     |\n",
      "|    num_episodes         | 221      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 28160    |\n",
      "|    total_time           | 20.6     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00377 |\n",
      "|    total_loss           | -0.0133  |\n",
      "|    value_loss           | 0.00464  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -123     |\n",
      "|    num_episodes         | 227      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 29440    |\n",
      "|    total_time           | 21.8     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00407 |\n",
      "|    total_loss           | -0.0108  |\n",
      "|    value_loss           | 0.00745  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -123     |\n",
      "|    num_episodes         | 232      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 30720    |\n",
      "|    total_time           | 23       |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.0076  |\n",
      "|    total_loss           | -0.0185  |\n",
      "|    value_loss           | 0.00325  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -124     |\n",
      "|    num_episodes         | 239      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 32000    |\n",
      "|    total_time           | 24.4     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00701 |\n",
      "|    total_loss           | -0.0163  |\n",
      "|    value_loss           | 0.00494  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -118     |\n",
      "|    num_episodes         | 245      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 33280    |\n",
      "|    total_time           | 26.1     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00929 |\n",
      "|    total_loss           | -0.0172  |\n",
      "|    value_loss           | 0.00627  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -118     |\n",
      "|    num_episodes         | 251      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 34560    |\n",
      "|    total_time           | 27.8     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00852 |\n",
      "|    total_loss           | -0.0153  |\n",
      "|    value_loss           | 0.00745  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -113     |\n",
      "|    num_episodes         | 255      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 35840    |\n",
      "|    total_time           | 29.6     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00326 |\n",
      "|    total_loss           | -0.0149  |\n",
      "|    value_loss           | 0.00255  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -110     |\n",
      "|    num_episodes         | 260      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 37120    |\n",
      "|    total_time           | 31.5     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00573 |\n",
      "|    total_loss           | -0.0128  |\n",
      "|    value_loss           | 0.00715  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -96.1    |\n",
      "|    num_episodes         | 267      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 38400    |\n",
      "|    total_time           | 33.4     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.0113  |\n",
      "|    total_loss           | -0.0235  |\n",
      "|    value_loss           | 0.00198  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -87.1    |\n",
      "|    num_episodes         | 275      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 39680    |\n",
      "|    total_time           | 34.2     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.0106  |\n",
      "|    total_loss           | -0.0167  |\n",
      "|    value_loss           | 0.00807  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -74.7    |\n",
      "|    num_episodes         | 281      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 40960    |\n",
      "|    total_time           | 35.2     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00495 |\n",
      "|    total_loss           | -0.0148  |\n",
      "|    value_loss           | 0.00435  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_rew_mean          | -65.6     |\n",
      "|    num_episodes         | 286       |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 42240     |\n",
      "|    total_time           | 36.4      |\n",
      "| train/                  |           |\n",
      "|    entropy_loss         | -1.42     |\n",
      "|    policy_gradient_loss | -7.23e-05 |\n",
      "|    total_loss           | -0.011    |\n",
      "|    value_loss           | 0.00323   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -59.5    |\n",
      "|    num_episodes         | 288      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 43520    |\n",
      "|    total_time           | 37.5     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00673 |\n",
      "|    total_loss           | -0.017   |\n",
      "|    value_loss           | 0.00394  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -58.4    |\n",
      "|    num_episodes         | 293      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 44800    |\n",
      "|    total_time           | 38.7     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.0068   |\n",
      "|    total_loss           | -0.00347 |\n",
      "|    value_loss           | 0.00392  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -54.7    |\n",
      "|    num_episodes         | 297      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 46080    |\n",
      "|    total_time           | 39.8     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00266  |\n",
      "|    total_loss           | -0.00848 |\n",
      "|    value_loss           | 0.00305  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -47.1    |\n",
      "|    num_episodes         | 303      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 47360    |\n",
      "|    total_time           | 40.8     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00396 |\n",
      "|    total_loss           | -0.0158  |\n",
      "|    value_loss           | 0.00234  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -45.4    |\n",
      "|    num_episodes         | 305      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 48640    |\n",
      "|    total_time           | 41.9     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00617  |\n",
      "|    total_loss           | -0.00705 |\n",
      "|    value_loss           | 0.000967 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -45.3    |\n",
      "|    num_episodes         | 306      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 49920    |\n",
      "|    total_time           | 43.1     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00312  |\n",
      "|    total_loss           | -0.00738 |\n",
      "|    value_loss           | 0.00368  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -38.8    |\n",
      "|    num_episodes         | 312      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 51200    |\n",
      "|    total_time           | 44.3     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00661 |\n",
      "|    total_loss           | -0.0189  |\n",
      "|    value_loss           | 0.00191  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -35.8    |\n",
      "|    num_episodes         | 315      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 52480    |\n",
      "|    total_time           | 45.4     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00889 |\n",
      "|    total_loss           | -0.0208  |\n",
      "|    value_loss           | 0.00227  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -34.5    |\n",
      "|    num_episodes         | 316      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 53760    |\n",
      "|    total_time           | 46.5     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00549  |\n",
      "|    total_loss           | -0.00719 |\n",
      "|    value_loss           | 0.00151  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_rew_mean          | -32.9     |\n",
      "|    num_episodes         | 317       |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 55040     |\n",
      "|    total_time           | 47.9      |\n",
      "| train/                  |           |\n",
      "|    entropy_loss         | -1.42     |\n",
      "|    policy_gradient_loss | -0.000816 |\n",
      "|    total_loss           | -0.0131   |\n",
      "|    value_loss           | 0.00186   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -30.1    |\n",
      "|    num_episodes         | 320      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 56320    |\n",
      "|    total_time           | 49.4     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.0116  |\n",
      "|    total_loss           | -0.0196  |\n",
      "|    value_loss           | 0.00621  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -28.5    |\n",
      "|    num_episodes         | 324      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 57600    |\n",
      "|    total_time           | 51       |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.0012   |\n",
      "|    total_loss           | -0.0116  |\n",
      "|    value_loss           | 0.00139  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_rew_mean          | -19.5     |\n",
      "|    num_episodes         | 328       |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 58880     |\n",
      "|    total_time           | 52.5      |\n",
      "| train/                  |           |\n",
      "|    entropy_loss         | -1.42     |\n",
      "|    policy_gradient_loss | -0.000533 |\n",
      "|    total_loss           | -0.0105   |\n",
      "|    value_loss           | 0.00418   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -18      |\n",
      "|    num_episodes         | 331      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 60160    |\n",
      "|    total_time           | 54.2     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.0055  |\n",
      "|    total_loss           | -0.0168  |\n",
      "|    value_loss           | 0.00286  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -14      |\n",
      "|    num_episodes         | 335      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 61440    |\n",
      "|    total_time           | 55.8     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00413 |\n",
      "|    total_loss           | -0.0174  |\n",
      "|    value_loss           | 0.000918 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -13      |\n",
      "|    num_episodes         | 341      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 62720    |\n",
      "|    total_time           | 57.1     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00742 |\n",
      "|    total_loss           | -0.021   |\n",
      "|    value_loss           | 0.000576 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -11.1    |\n",
      "|    num_episodes         | 349      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 64000    |\n",
      "|    total_time           | 57.9     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00552 |\n",
      "|    total_loss           | -0.0127  |\n",
      "|    value_loss           | 0.00702  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -8.81    |\n",
      "|    num_episodes         | 359      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 65280    |\n",
      "|    total_time           | 58.7     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00156 |\n",
      "|    total_loss           | -0.0125  |\n",
      "|    value_loss           | 0.00321  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -7.53    |\n",
      "|    num_episodes         | 366      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 66560    |\n",
      "|    total_time           | 59.6     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00377 |\n",
      "|    total_loss           | -0.0152  |\n",
      "|    value_loss           | 0.00272  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -7.63    |\n",
      "|    num_episodes         | 371      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 67840    |\n",
      "|    total_time           | 60.6     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.0107  |\n",
      "|    total_loss           | -0.0235  |\n",
      "|    value_loss           | 0.00137  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -6.14    |\n",
      "|    num_episodes         | 374      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 69120    |\n",
      "|    total_time           | 61.6     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00212 |\n",
      "|    total_loss           | -0.0157  |\n",
      "|    value_loss           | 0.000632 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -5.54    |\n",
      "|    num_episodes         | 377      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 70400    |\n",
      "|    total_time           | 62.7     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00523 |\n",
      "|    total_loss           | -0.0183  |\n",
      "|    value_loss           | 0.00114  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -5.26    |\n",
      "|    num_episodes         | 381      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 71680    |\n",
      "|    total_time           | 63.8     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00325  |\n",
      "|    total_loss           | -0.00984 |\n",
      "|    value_loss           | 0.0011   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -4.82    |\n",
      "|    num_episodes         | 386      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 72960    |\n",
      "|    total_time           | 64.8     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.0111  |\n",
      "|    total_loss           | -0.0236  |\n",
      "|    value_loss           | 0.0017   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -4.69    |\n",
      "|    num_episodes         | 391      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 74240    |\n",
      "|    total_time           | 65.8     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.006   |\n",
      "|    total_loss           | -0.0182  |\n",
      "|    value_loss           | 0.00198  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -5.44    |\n",
      "|    num_episodes         | 396      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 75520    |\n",
      "|    total_time           | 66.8     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00286 |\n",
      "|    total_loss           | -0.0108  |\n",
      "|    value_loss           | 0.00629  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -6.59    |\n",
      "|    num_episodes         | 402      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 76800    |\n",
      "|    total_time           | 67.8     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00529 |\n",
      "|    total_loss           | -0.0157  |\n",
      "|    value_loss           | 0.00379  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -5.1     |\n",
      "|    num_episodes         | 406      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 78080    |\n",
      "|    total_time           | 68.9     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00831 |\n",
      "|    total_loss           | -0.0177  |\n",
      "|    value_loss           | 0.00483  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -4.82    |\n",
      "|    num_episodes         | 409      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 79360    |\n",
      "|    total_time           | 70       |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00488  |\n",
      "|    total_loss           | -0.00858 |\n",
      "|    value_loss           | 0.000736 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -3.15    |\n",
      "|    num_episodes         | 412      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 80640    |\n",
      "|    total_time           | 71.1     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00486 |\n",
      "|    total_loss           | -0.0169  |\n",
      "|    value_loss           | 0.00213  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -1.9     |\n",
      "|    num_episodes         | 414      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 81920    |\n",
      "|    total_time           | 72.2     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00251 |\n",
      "|    total_loss           | -0.0165  |\n",
      "|    value_loss           | 0.000232 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -1.1     |\n",
      "|    num_episodes         | 419      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 83200    |\n",
      "|    total_time           | 73.2     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00233 |\n",
      "|    total_loss           | -0.0141  |\n",
      "|    value_loss           | 0.00244  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -0.661   |\n",
      "|    num_episodes         | 420      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 84480    |\n",
      "|    total_time           | 74.4     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00287 |\n",
      "|    total_loss           | -0.0166  |\n",
      "|    value_loss           | 0.000443 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -0.661   |\n",
      "|    num_episodes         | 420      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 85760    |\n",
      "|    total_time           | 75.7     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00224  |\n",
      "|    total_loss           | -0.0108  |\n",
      "|    value_loss           | 0.00114  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 5.65     |\n",
      "|    num_episodes         | 423      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 87040    |\n",
      "|    total_time           | 76.9     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.000889 |\n",
      "|    total_loss           | -0.0124  |\n",
      "|    value_loss           | 0.00092  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 6.92     |\n",
      "|    num_episodes         | 424      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 88320    |\n",
      "|    total_time           | 78.1     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00432  |\n",
      "|    total_loss           | -0.00842 |\n",
      "|    value_loss           | 0.00145  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 6.92     |\n",
      "|    num_episodes         | 424      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 89600    |\n",
      "|    total_time           | 79.5     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00499  |\n",
      "|    total_loss           | -0.00883 |\n",
      "|    value_loss           | 0.000369 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 8.92     |\n",
      "|    num_episodes         | 427      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 90880    |\n",
      "|    total_time           | 80.6     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00542 |\n",
      "|    total_loss           | -0.0181  |\n",
      "|    value_loss           | 0.00146  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 10.4     |\n",
      "|    num_episodes         | 428      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 92160    |\n",
      "|    total_time           | 81.9     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00171  |\n",
      "|    total_loss           | -0.0109  |\n",
      "|    value_loss           | 0.00153  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_rew_mean          | 12.4      |\n",
      "|    num_episodes         | 429       |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 93440     |\n",
      "|    total_time           | 83.4      |\n",
      "| train/                  |           |\n",
      "|    entropy_loss         | -1.42     |\n",
      "|    policy_gradient_loss | -0.000775 |\n",
      "|    total_loss           | -0.0143   |\n",
      "|    value_loss           | 0.000625  |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 15.6     |\n",
      "|    num_episodes         | 432      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 94720    |\n",
      "|    total_time           | 84.8     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00117 |\n",
      "|    total_loss           | -0.0129  |\n",
      "|    value_loss           | 0.00248  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 17.1     |\n",
      "|    num_episodes         | 435      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 96000    |\n",
      "|    total_time           | 85.8     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.002    |\n",
      "|    total_loss           | -0.0117  |\n",
      "|    value_loss           | 0.000476 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 18.9     |\n",
      "|    num_episodes         | 436      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 97280    |\n",
      "|    total_time           | 86.8     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00227 |\n",
      "|    total_loss           | -0.0161  |\n",
      "|    value_loss           | 0.000384 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_rew_mean          | 21.9      |\n",
      "|    num_episodes         | 437       |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 98560     |\n",
      "|    total_time           | 87.9      |\n",
      "| train/                  |           |\n",
      "|    entropy_loss         | -1.42     |\n",
      "|    policy_gradient_loss | -0.000746 |\n",
      "|    total_loss           | -0.0145   |\n",
      "|    value_loss           | 0.00045   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 25.3     |\n",
      "|    num_episodes         | 440      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 99840    |\n",
      "|    total_time           | 88.9     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00745 |\n",
      "|    total_loss           | -0.0166  |\n",
      "|    value_loss           | 0.00505  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 28       |\n",
      "|    num_episodes         | 443      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 101120   |\n",
      "|    total_time           | 90       |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00587  |\n",
      "|    total_loss           | -0.00749 |\n",
      "|    value_loss           | 0.000827 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 29.7     |\n",
      "|    num_episodes         | 444      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 102400   |\n",
      "|    total_time           | 91.2     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00498 |\n",
      "|    total_loss           | -0.0166  |\n",
      "|    value_loss           | 0.0026   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 30.9     |\n",
      "|    num_episodes         | 445      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 103680   |\n",
      "|    total_time           | 92.4     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00311 |\n",
      "|    total_loss           | -0.0148  |\n",
      "|    value_loss           | 0.00255  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 34.6     |\n",
      "|    num_episodes         | 447      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 104960   |\n",
      "|    total_time           | 93.7     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00402 |\n",
      "|    total_loss           | -0.0176  |\n",
      "|    value_loss           | 0.000592 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 34.6     |\n",
      "|    num_episodes         | 447      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 106240   |\n",
      "|    total_time           | 94.7     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00517 |\n",
      "|    total_loss           | -0.0182  |\n",
      "|    value_loss           | 0.00118  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 37.7     |\n",
      "|    num_episodes         | 449      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 107520   |\n",
      "|    total_time           | 96       |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00307 |\n",
      "|    total_loss           | -0.0157  |\n",
      "|    value_loss           | 0.00153  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 38.8     |\n",
      "|    num_episodes         | 450      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 108800   |\n",
      "|    total_time           | 97.1     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00779 |\n",
      "|    total_loss           | -0.0202  |\n",
      "|    value_loss           | 0.00175  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 40.9     |\n",
      "|    num_episodes         | 451      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 110080   |\n",
      "|    total_time           | 98.2     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00125  |\n",
      "|    total_loss           | -0.012   |\n",
      "|    value_loss           | 0.000923 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 41.6     |\n",
      "|    num_episodes         | 453      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 111360   |\n",
      "|    total_time           | 99.6     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.0042  |\n",
      "|    total_loss           | -0.018   |\n",
      "|    value_loss           | 0.000375 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 43.8     |\n",
      "|    num_episodes         | 455      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 112640   |\n",
      "|    total_time           | 101      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00108 |\n",
      "|    total_loss           | -0.0145  |\n",
      "|    value_loss           | 0.000807 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 44.3     |\n",
      "|    num_episodes         | 456      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 113920   |\n",
      "|    total_time           | 102      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00641 |\n",
      "|    total_loss           | -0.0203  |\n",
      "|    value_loss           | 0.000307 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 45.5     |\n",
      "|    num_episodes         | 457      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 115200   |\n",
      "|    total_time           | 104      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.000955 |\n",
      "|    total_loss           | -0.0118  |\n",
      "|    value_loss           | 0.00147  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 49.1     |\n",
      "|    num_episodes         | 459      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 116480   |\n",
      "|    total_time           | 105      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.0014   |\n",
      "|    total_loss           | -0.0123  |\n",
      "|    value_loss           | 0.000465 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 50.4     |\n",
      "|    num_episodes         | 460      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 117760   |\n",
      "|    total_time           | 107      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00157 |\n",
      "|    total_loss           | -0.0155  |\n",
      "|    value_loss           | 0.000213 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 51.6     |\n",
      "|    num_episodes         | 461      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 119040   |\n",
      "|    total_time           | 108      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00397 |\n",
      "|    total_loss           | -0.0181  |\n",
      "|    value_loss           | 0.000105 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 54.4     |\n",
      "|    num_episodes         | 464      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 120320   |\n",
      "|    total_time           | 109      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.0135  |\n",
      "|    total_loss           | -0.0231  |\n",
      "|    value_loss           | 0.00453  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 55.8     |\n",
      "|    num_episodes         | 466      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 121600   |\n",
      "|    total_time           | 110      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00573 |\n",
      "|    total_loss           | -0.0187  |\n",
      "|    value_loss           | 0.00124  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 58.4     |\n",
      "|    num_episodes         | 468      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 122880   |\n",
      "|    total_time           | 111      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00253  |\n",
      "|    total_loss           | -0.0108  |\n",
      "|    value_loss           | 0.000863 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 60.6     |\n",
      "|    num_episodes         | 470      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 124160   |\n",
      "|    total_time           | 113      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00545  |\n",
      "|    total_loss           | -0.00674 |\n",
      "|    value_loss           | 0.002    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 59.7     |\n",
      "|    num_episodes         | 472      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 125440   |\n",
      "|    total_time           | 114      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00554 |\n",
      "|    total_loss           | -0.0167  |\n",
      "|    value_loss           | 0.00307  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 59.7     |\n",
      "|    num_episodes         | 472      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 126720   |\n",
      "|    total_time           | 115      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00119  |\n",
      "|    total_loss           | -0.0129  |\n",
      "|    value_loss           | 7.86e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 61.8     |\n",
      "|    num_episodes         | 476      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 128000   |\n",
      "|    total_time           | 116      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.0014  |\n",
      "|    total_loss           | -0.01    |\n",
      "|    value_loss           | 0.00555  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 63.2     |\n",
      "|    num_episodes         | 479      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 129280   |\n",
      "|    total_time           | 117      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00291 |\n",
      "|    total_loss           | -0.0166  |\n",
      "|    value_loss           | 0.000536 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 65       |\n",
      "|    num_episodes         | 481      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 130560   |\n",
      "|    total_time           | 118      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.000341 |\n",
      "|    total_loss           | -0.0109  |\n",
      "|    value_loss           | 0.00293  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 65       |\n",
      "|    num_episodes         | 481      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 131840   |\n",
      "|    total_time           | 120      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00078  |\n",
      "|    total_loss           | -0.013   |\n",
      "|    value_loss           | 0.0004   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 68.4     |\n",
      "|    num_episodes         | 484      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 133120   |\n",
      "|    total_time           | 121      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00144  |\n",
      "|    total_loss           | -0.0116  |\n",
      "|    value_loss           | 0.00116  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 68.3     |\n",
      "|    num_episodes         | 485      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 134400   |\n",
      "|    total_time           | 122      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00328  |\n",
      "|    total_loss           | -0.00956 |\n",
      "|    value_loss           | 0.00135  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 68.3     |\n",
      "|    num_episodes         | 485      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 135680   |\n",
      "|    total_time           | 123      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00186 |\n",
      "|    total_loss           | -0.015   |\n",
      "|    value_loss           | 0.00104  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 73.2     |\n",
      "|    num_episodes         | 490      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 136960   |\n",
      "|    total_time           | 124      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00801 |\n",
      "|    total_loss           | -0.0154  |\n",
      "|    value_loss           | 0.00681  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 72.9     |\n",
      "|    num_episodes         | 495      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 138240   |\n",
      "|    total_time           | 125      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00355  |\n",
      "|    total_loss           | -0.0075  |\n",
      "|    value_loss           | 0.00314  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 73.8     |\n",
      "|    num_episodes         | 498      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 139520   |\n",
      "|    total_time           | 126      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00129 |\n",
      "|    total_loss           | -0.0107  |\n",
      "|    value_loss           | 0.00475  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 74.7     |\n",
      "|    num_episodes         | 499      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 140800   |\n",
      "|    total_time           | 127      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00236 |\n",
      "|    total_loss           | -0.0155  |\n",
      "|    value_loss           | 0.00104  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 76.3     |\n",
      "|    num_episodes         | 500      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 142080   |\n",
      "|    total_time           | 129      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00336 |\n",
      "|    total_loss           | -0.0175  |\n",
      "|    value_loss           | 9.39e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 78.3     |\n",
      "|    num_episodes         | 505      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 143360   |\n",
      "|    total_time           | 130      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00582 |\n",
      "|    total_loss           | -0.0174  |\n",
      "|    value_loss           | 0.00258  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_rew_mean          | 79.6      |\n",
      "|    num_episodes         | 508       |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 144640    |\n",
      "|    total_time           | 131       |\n",
      "| train/                  |           |\n",
      "|    entropy_loss         | -1.42     |\n",
      "|    policy_gradient_loss | -0.000769 |\n",
      "|    total_loss           | -0.0134   |\n",
      "|    value_loss           | 0.00157   |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 79.6     |\n",
      "|    num_episodes         | 508      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 145920   |\n",
      "|    total_time           | 132      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.0018  |\n",
      "|    total_loss           | -0.0154  |\n",
      "|    value_loss           | 0.00059  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 79.8     |\n",
      "|    num_episodes         | 509      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 147200   |\n",
      "|    total_time           | 133      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00745 |\n",
      "|    total_loss           | -0.018   |\n",
      "|    value_loss           | 0.00365  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 83.3     |\n",
      "|    num_episodes         | 515      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 148480   |\n",
      "|    total_time           | 134      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00766 |\n",
      "|    total_loss           | -0.0189  |\n",
      "|    value_loss           | 0.00293  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 81.5     |\n",
      "|    num_episodes         | 519      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 149760   |\n",
      "|    total_time           | 135      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00976 |\n",
      "|    total_loss           | -0.0231  |\n",
      "|    value_loss           | 0.000804 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 81.5     |\n",
      "|    num_episodes         | 519      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 151040   |\n",
      "|    total_time           | 136      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00678  |\n",
      "|    total_loss           | -0.00736 |\n",
      "|    value_loss           | 5.42e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 81.5     |\n",
      "|    num_episodes         | 519      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 152320   |\n",
      "|    total_time           | 138      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.0076  |\n",
      "|    total_loss           | -0.0197  |\n",
      "|    value_loss           | 0.0021   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 81.9     |\n",
      "|    num_episodes         | 524      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 153600   |\n",
      "|    total_time           | 139      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00551 |\n",
      "|    total_loss           | -0.0188  |\n",
      "|    value_loss           | 0.000908 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 79.1     |\n",
      "|    num_episodes         | 526      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 154880   |\n",
      "|    total_time           | 140      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00601 |\n",
      "|    total_loss           | -0.0197  |\n",
      "|    value_loss           | 0.000504 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 76.8     |\n",
      "|    num_episodes         | 528      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 156160   |\n",
      "|    total_time           | 141      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.0066  |\n",
      "|    total_loss           | -0.0171  |\n",
      "|    value_loss           | 0.00374  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 76.5     |\n",
      "|    num_episodes         | 533      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 157440   |\n",
      "|    total_time           | 142      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00661 |\n",
      "|    total_loss           | -0.0154  |\n",
      "|    value_loss           | 0.00536  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 76.5     |\n",
      "|    num_episodes         | 533      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 158720   |\n",
      "|    total_time           | 144      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00185 |\n",
      "|    total_loss           | -0.0145  |\n",
      "|    value_loss           | 0.00156  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 77.1     |\n",
      "|    num_episodes         | 534      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 160000   |\n",
      "|    total_time           | 145      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00374  |\n",
      "|    total_loss           | -0.0104  |\n",
      "|    value_loss           | 9.96e-05 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 75.9     |\n",
      "|    num_episodes         | 537      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 161280   |\n",
      "|    total_time           | 146      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00368 |\n",
      "|    total_loss           | -0.0109  |\n",
      "|    value_loss           | 0.00697  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 75.5     |\n",
      "|    num_episodes         | 539      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 162560   |\n",
      "|    total_time           | 147      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00415 |\n",
      "|    total_loss           | -0.0168  |\n",
      "|    value_loss           | 0.00155  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 75.5     |\n",
      "|    num_episodes         | 539      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 163840   |\n",
      "|    total_time           | 149      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.000808 |\n",
      "|    total_loss           | -0.0129  |\n",
      "|    value_loss           | 0.000453 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 75.6     |\n",
      "|    num_episodes         | 541      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 165120   |\n",
      "|    total_time           | 150      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00543 |\n",
      "|    total_loss           | -0.0192  |\n",
      "|    value_loss           | 0.000435 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 76       |\n",
      "|    num_episodes         | 543      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 166400   |\n",
      "|    total_time           | 151      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00753 |\n",
      "|    total_loss           | -0.0206  |\n",
      "|    value_loss           | 0.00111  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 76       |\n",
      "|    num_episodes         | 543      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 167680   |\n",
      "|    total_time           | 153      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00781 |\n",
      "|    total_loss           | -0.0215  |\n",
      "|    value_loss           | 0.000501 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 76.2     |\n",
      "|    num_episodes         | 544      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 168960   |\n",
      "|    total_time           | 154      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 8.9e-05  |\n",
      "|    total_loss           | -0.014   |\n",
      "|    value_loss           | 0.000115 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 75.5     |\n",
      "|    num_episodes         | 547      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 170240   |\n",
      "|    total_time           | 155      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00564  |\n",
      "|    total_loss           | -0.0075  |\n",
      "|    value_loss           | 0.00105  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 76       |\n",
      "|    num_episodes         | 548      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 171520   |\n",
      "|    total_time           | 157      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00248 |\n",
      "|    total_loss           | -0.0164  |\n",
      "|    value_loss           | 0.00023  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 75.8     |\n",
      "|    num_episodes         | 549      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 172800   |\n",
      "|    total_time           | 158      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00349 |\n",
      "|    total_loss           | -0.0168  |\n",
      "|    value_loss           | 0.000846 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 76.3     |\n",
      "|    num_episodes         | 551      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 174080   |\n",
      "|    total_time           | 159      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00489 |\n",
      "|    total_loss           | -0.0166  |\n",
      "|    value_loss           | 0.00247  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 76.3     |\n",
      "|    num_episodes         | 552      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 175360   |\n",
      "|    total_time           | 161      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00974 |\n",
      "|    total_loss           | -0.0233  |\n",
      "|    value_loss           | 0.000586 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 78.8     |\n",
      "|    num_episodes         | 553      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 176640   |\n",
      "|    total_time           | 162      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00179 |\n",
      "|    total_loss           | -0.0148  |\n",
      "|    value_loss           | 0.00123  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 79.3     |\n",
      "|    num_episodes         | 555      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 177920   |\n",
      "|    total_time           | 164      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00867 |\n",
      "|    total_loss           | -0.0206  |\n",
      "|    value_loss           | 0.00223  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 78.3     |\n",
      "|    num_episodes         | 556      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 179200   |\n",
      "|    total_time           | 165      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00272 |\n",
      "|    total_loss           | -0.0163  |\n",
      "|    value_loss           | 0.000613 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 79       |\n",
      "|    num_episodes         | 558      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 180480   |\n",
      "|    total_time           | 166      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00438 |\n",
      "|    total_loss           | -0.0178  |\n",
      "|    value_loss           | 0.000808 |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 79       |\n",
      "|    num_episodes         | 559      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 181760   |\n",
      "|    total_time           | 168      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | 0.00137  |\n",
      "|    total_loss           | -0.0126  |\n",
      "|    value_loss           | 0.00023  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 79.2     |\n",
      "|    num_episodes         | 560      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 183040   |\n",
      "|    total_time           | 169      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.42    |\n",
      "|    policy_gradient_loss | -0.00663 |\n",
      "|    total_loss           | -0.0202  |\n",
      "|    value_loss           | 0.000591 |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_rew_mean          | 79        |\n",
      "|    num_episodes         | 562       |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 184320    |\n",
      "|    total_time           | 171       |\n",
      "| train/                  |           |\n",
      "|    entropy_loss         | -1.42     |\n",
      "|    policy_gradient_loss | -0.000679 |\n",
      "|    total_loss           | -0.0136   |\n",
      "|    value_loss           | 0.00127   |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d8510e03db63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPPO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.003\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e+7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\MSc Data Analytics\\Reinforcement Learning\\PPO\\ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, log_interval)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\MSc Data Analytics\\Reinforcement Learning\\PPO\\ppo.py\u001b[0m in \u001b[0;36mcollect_samples\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0mlog_probs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_envs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrollout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_obs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdones\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = PPO(env = env, lr = 0.003, nstep = 64, batch_size = 32, hidden_size = 32, n_epochs = 4)\n",
    "model.learn(total_timesteps = 1e+7, log_interval = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = PPO_RND(env = env, lr = 0.0003, nstep = 64, batch_size = 32, max_grad_norm = 1, \n",
    "                hidden_size = 128, rnd_hidden_size = 64, n_epochs = 4, vf_coef = 1, ent_coef = 0.2)\n",
    "model.learn(total_timesteps = 1e+7, log_interval = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO_ICM(env = env, lr = 0.0003, icm_lr = 0.0003, nstep = 64, batch_size = 64, max_grad_norm = 1, \n",
    "                hidden_size = 64, icm_hidden_size = 64, int_vf_coef = 1, vf_coef = 0, n_epochs = 4)\n",
    "model.learn(total_timesteps = 1e+7, log_interval = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(torch.Tensor([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from logger import *\n",
    "\n",
    "my_dict = {'T1': 'A', 'T2': 'B', 'T4': 'D'}\n",
    "\n",
    "with open('./file.csv', 'a') as f:\n",
    "    w = csv.DictWriter(f, my_dict.keys())\n",
    "    w.writeheader()\n",
    "    w.writerow(my_dict)\n",
    "    f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "writer = HumanOutputFormat(sys.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"train/mama\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.split('/')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
