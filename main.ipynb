{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from models import *\n",
    "from ppo import PPO, PPO_RND, PPO_ICM\n",
    "from buffer import RolloutStorage\n",
    "from env import *\n",
    "\n",
    "import torch\n",
    "import torch.distributions as distributions\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "from stable_baselines3.common.cmd_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import vec_normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybulletgym\n",
    "env = make_vec_env(\"CartPole-v0\", 1)\n",
    "env = VecNormalize(env)\n",
    "model = PPO(env = env, lr = 0.0003, nstep = 256, batch_size = 256)\n",
    "model.learn(total_timesteps = 1e+7, log_interval = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pybulletgym\n",
    "env = make_vec_env(\"MountainCar-v0\", 4, vec_env_cls = SubprocVecEnv)\n",
    "env = VecNormalize(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO_ICM(env = env, lr = 0.0003, icm_lr = 0.0003, nstep = 128, batch_size = 128, max_grad_norm = 1, \n",
    "                hidden_size = 32, icm_hidden_size = 32)\n",
    "model.learn(total_timesteps = 1e+7, log_interval = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------\n",
      "| Progress                | 0.05%    |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 200      |\n",
      "|    ep_rew_mean          | -200     |\n",
      "|    num_episodes         | 24       |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 5120     |\n",
      "|    total_time           | 5.43     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.06    |\n",
      "|    intrinsic_loss       | 0.198    |\n",
      "|    policy_gradient_loss | -0.00495 |\n",
      "|    total_loss           | 0.12     |\n",
      "|    value_loss           | 0.198    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 0.1%     |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 200      |\n",
      "|    ep_rew_mean          | -200     |\n",
      "|    num_episodes         | 48       |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 10240    |\n",
      "|    total_time           | 11.7     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.673   |\n",
      "|    intrinsic_loss       | 0.193    |\n",
      "|    policy_gradient_loss | -0.0106  |\n",
      "|    total_loss           | 0.125    |\n",
      "|    value_loss           | 0.193    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 0.15%    |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 200      |\n",
      "|    ep_rew_mean          | -200     |\n",
      "|    num_episodes         | 76       |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 15360    |\n",
      "|    total_time           | 17.9     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.646   |\n",
      "|    intrinsic_loss       | 0.169    |\n",
      "|    policy_gradient_loss | -0.00426 |\n",
      "|    total_loss           | 0.124    |\n",
      "|    value_loss           | 0.169    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 0.2%     |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 199      |\n",
      "|    ep_rew_mean          | -199     |\n",
      "|    num_episodes         | 100      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 20480    |\n",
      "|    total_time           | 24.6     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.559   |\n",
      "|    intrinsic_loss       | 0.175    |\n",
      "|    policy_gradient_loss | -0.00182 |\n",
      "|    total_loss           | 0.121    |\n",
      "|    value_loss           | 0.175    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 0.25%    |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 186      |\n",
      "|    ep_rew_mean          | -186     |\n",
      "|    num_episodes         | 134      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 25600    |\n",
      "|    total_time           | 31.1     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.399   |\n",
      "|    intrinsic_loss       | 0.179    |\n",
      "|    policy_gradient_loss | -0.0101  |\n",
      "|    total_loss           | 0.122    |\n",
      "|    value_loss           | 0.179    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 0.3%     |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 170      |\n",
      "|    ep_rew_mean          | -170     |\n",
      "|    num_episodes         | 167      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 30720    |\n",
      "|    total_time           | 37.7     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.446   |\n",
      "|    intrinsic_loss       | 0.17     |\n",
      "|    policy_gradient_loss | -0.00343 |\n",
      "|    total_loss           | 0.121    |\n",
      "|    value_loss           | 0.17     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 0.35%    |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 153      |\n",
      "|    ep_rew_mean          | -153     |\n",
      "|    num_episodes         | 202      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 35840    |\n",
      "|    total_time           | 44.5     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.268   |\n",
      "|    intrinsic_loss       | 0.162    |\n",
      "|    policy_gradient_loss | -0.00298 |\n",
      "|    total_loss           | 0.117    |\n",
      "|    value_loss           | 0.162    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 0.4%     |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 143      |\n",
      "|    ep_rew_mean          | -143     |\n",
      "|    num_episodes         | 242      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 40960    |\n",
      "|    total_time           | 50.8     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.221   |\n",
      "|    intrinsic_loss       | 0.171    |\n",
      "|    policy_gradient_loss | -0.00275 |\n",
      "|    total_loss           | 0.125    |\n",
      "|    value_loss           | 0.171    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 0.46%    |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 132      |\n",
      "|    ep_rew_mean          | -132     |\n",
      "|    num_episodes         | 282      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 46080    |\n",
      "|    total_time           | 57.7     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.124   |\n",
      "|    intrinsic_loss       | 0.174    |\n",
      "|    policy_gradient_loss | -0.00355 |\n",
      "|    total_loss           | 0.125    |\n",
      "|    value_loss           | 0.174    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| Progress                | 0.51%     |\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 126       |\n",
      "|    ep_rew_mean          | -126      |\n",
      "|    num_episodes         | 323       |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 51200     |\n",
      "|    total_time           | 64.1      |\n",
      "| train/                  |           |\n",
      "|    entropy_loss         | -0.159    |\n",
      "|    intrinsic_loss       | 0.159     |\n",
      "|    policy_gradient_loss | -0.000801 |\n",
      "|    total_loss           | 0.119     |\n",
      "|    value_loss           | 0.159     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| Progress                | 0.56%     |\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 126       |\n",
      "|    ep_rew_mean          | -126      |\n",
      "|    num_episodes         | 364       |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 56320     |\n",
      "|    total_time           | 70.5      |\n",
      "| train/                  |           |\n",
      "|    entropy_loss         | -0.115    |\n",
      "|    intrinsic_loss       | 0.17      |\n",
      "|    policy_gradient_loss | -0.000844 |\n",
      "|    total_loss           | 0.126     |\n",
      "|    value_loss           | 0.17      |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 0.61%    |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 122      |\n",
      "|    ep_rew_mean          | -122     |\n",
      "|    num_episodes         | 405      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 61440    |\n",
      "|    total_time           | 76.9     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.11    |\n",
      "|    intrinsic_loss       | 0.167    |\n",
      "|    policy_gradient_loss | -0.00134 |\n",
      "|    total_loss           | 0.126    |\n",
      "|    value_loss           | 0.167    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| Progress                | 0.66%     |\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 124       |\n",
      "|    ep_rew_mean          | -124      |\n",
      "|    num_episodes         | 447       |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 66560     |\n",
      "|    total_time           | 83.3      |\n",
      "| train/                  |           |\n",
      "|    entropy_loss         | -0.114    |\n",
      "|    intrinsic_loss       | 0.165     |\n",
      "|    policy_gradient_loss | -0.000295 |\n",
      "|    total_loss           | 0.123     |\n",
      "|    value_loss           | 0.165     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| Progress                | 0.71%     |\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 122       |\n",
      "|    ep_rew_mean          | -122      |\n",
      "|    num_episodes         | 489       |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 71680     |\n",
      "|    total_time           | 90        |\n",
      "| train/                  |           |\n",
      "|    entropy_loss         | -0.189    |\n",
      "|    intrinsic_loss       | 0.175     |\n",
      "|    policy_gradient_loss | -0.000981 |\n",
      "|    total_loss           | 0.131     |\n",
      "|    value_loss           | 0.175     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 0.76%    |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 123      |\n",
      "|    ep_rew_mean          | -123     |\n",
      "|    num_episodes         | 532      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 76800    |\n",
      "|    total_time           | 96.5     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.159   |\n",
      "|    intrinsic_loss       | 0.163    |\n",
      "|    policy_gradient_loss | -0.00059 |\n",
      "|    total_loss           | 0.122    |\n",
      "|    value_loss           | 0.163    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 0.81%    |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 121      |\n",
      "|    ep_rew_mean          | -121     |\n",
      "|    num_episodes         | 573      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 81920    |\n",
      "|    total_time           | 103      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.223   |\n",
      "|    intrinsic_loss       | 0.183    |\n",
      "|    policy_gradient_loss | -0.00216 |\n",
      "|    total_loss           | 0.133    |\n",
      "|    value_loss           | 0.183    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| Progress                | 0.87%     |\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 121       |\n",
      "|    ep_rew_mean          | -121      |\n",
      "|    num_episodes         | 617       |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 87040     |\n",
      "|    total_time           | 110       |\n",
      "| train/                  |           |\n",
      "|    entropy_loss         | -0.127    |\n",
      "|    intrinsic_loss       | 0.17      |\n",
      "|    policy_gradient_loss | -0.000866 |\n",
      "|    total_loss           | 0.127     |\n",
      "|    value_loss           | 0.17      |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| Progress                | 0.92%     |\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 117       |\n",
      "|    ep_rew_mean          | -117      |\n",
      "|    num_episodes         | 661       |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 92160     |\n",
      "|    total_time           | 117       |\n",
      "| train/                  |           |\n",
      "|    entropy_loss         | -0.161    |\n",
      "|    intrinsic_loss       | 0.182     |\n",
      "|    policy_gradient_loss | -0.000531 |\n",
      "|    total_loss           | 0.135     |\n",
      "|    value_loss           | 0.182     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 0.97%    |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 117      |\n",
      "|    ep_rew_mean          | -117     |\n",
      "|    num_episodes         | 702      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 97280    |\n",
      "|    total_time           | 124      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.0967  |\n",
      "|    intrinsic_loss       | 0.179    |\n",
      "|    policy_gradient_loss | -0.00182 |\n",
      "|    total_loss           | 0.132    |\n",
      "|    value_loss           | 0.179    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 1.02%    |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 121      |\n",
      "|    ep_rew_mean          | -121     |\n",
      "|    num_episodes         | 745      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 102400   |\n",
      "|    total_time           | 131      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.0922  |\n",
      "|    intrinsic_loss       | 0.167    |\n",
      "|    policy_gradient_loss | -0.00023 |\n",
      "|    total_loss           | 0.126    |\n",
      "|    value_loss           | 0.167    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 1.07%    |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 121      |\n",
      "|    ep_rew_mean          | -121     |\n",
      "|    num_episodes         | 788      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 107520   |\n",
      "|    total_time           | 138      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.061   |\n",
      "|    intrinsic_loss       | 0.182    |\n",
      "|    policy_gradient_loss | -0.00107 |\n",
      "|    total_loss           | 0.137    |\n",
      "|    value_loss           | 0.182    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 1.12%    |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 115      |\n",
      "|    ep_rew_mean          | -115     |\n",
      "|    num_episodes         | 834      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 112640   |\n",
      "|    total_time           | 144      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.0893  |\n",
      "|    intrinsic_loss       | 0.175    |\n",
      "|    policy_gradient_loss | -0.00084 |\n",
      "|    total_loss           | 0.129    |\n",
      "|    value_loss           | 0.175    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 1.17%    |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 113      |\n",
      "|    ep_rew_mean          | -113     |\n",
      "|    num_episodes         | 879      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 117760   |\n",
      "|    total_time           | 151      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.0852  |\n",
      "|    intrinsic_loss       | 0.169    |\n",
      "|    policy_gradient_loss | -0.00129 |\n",
      "|    total_loss           | 0.126    |\n",
      "|    value_loss           | 0.169    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| Progress                | 1.22%     |\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 110       |\n",
      "|    ep_rew_mean          | -110      |\n",
      "|    num_episodes         | 927       |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 122880    |\n",
      "|    total_time           | 158       |\n",
      "| train/                  |           |\n",
      "|    entropy_loss         | -0.0942   |\n",
      "|    intrinsic_loss       | 0.174     |\n",
      "|    policy_gradient_loss | -0.000375 |\n",
      "|    total_loss           | 0.13      |\n",
      "|    value_loss           | 0.174     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 1.27%    |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 111      |\n",
      "|    ep_rew_mean          | -111     |\n",
      "|    num_episodes         | 971      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 128000   |\n",
      "|    total_time           | 165      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.101   |\n",
      "|    intrinsic_loss       | 0.173    |\n",
      "|    policy_gradient_loss | -0.00236 |\n",
      "|    total_loss           | 0.126    |\n",
      "|    value_loss           | 0.173    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 1.33%    |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 113      |\n",
      "|    ep_rew_mean          | -113     |\n",
      "|    num_episodes         | 1019     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 133120   |\n",
      "|    total_time           | 172      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.0781  |\n",
      "|    intrinsic_loss       | 0.176    |\n",
      "|    policy_gradient_loss | -0.00102 |\n",
      "|    total_loss           | 0.131    |\n",
      "|    value_loss           | 0.176    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| Progress                | 1.38%     |\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 114       |\n",
      "|    ep_rew_mean          | -114      |\n",
      "|    num_episodes         | 1062      |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 138240    |\n",
      "|    total_time           | 179       |\n",
      "| train/                  |           |\n",
      "|    entropy_loss         | -0.163    |\n",
      "|    intrinsic_loss       | 0.176     |\n",
      "|    policy_gradient_loss | -0.000793 |\n",
      "|    total_loss           | 0.13      |\n",
      "|    value_loss           | 0.176     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| Progress                | 1.43%     |\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 113       |\n",
      "|    ep_rew_mean          | -113      |\n",
      "|    num_episodes         | 1107      |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 143360    |\n",
      "|    total_time           | 186       |\n",
      "| train/                  |           |\n",
      "|    entropy_loss         | -0.12     |\n",
      "|    intrinsic_loss       | 0.168     |\n",
      "|    policy_gradient_loss | -0.000595 |\n",
      "|    total_loss           | 0.125     |\n",
      "|    value_loss           | 0.168     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 1.48%    |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 112      |\n",
      "|    ep_rew_mean          | -112     |\n",
      "|    num_episodes         | 1152     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 148480   |\n",
      "|    total_time           | 193      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.089   |\n",
      "|    intrinsic_loss       | 0.187    |\n",
      "|    policy_gradient_loss | -0.0127  |\n",
      "|    total_loss           | 0.128    |\n",
      "|    value_loss           | 0.187    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| Progress                | 1.53%     |\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 118       |\n",
      "|    ep_rew_mean          | -118      |\n",
      "|    num_episodes         | 1193      |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 153600    |\n",
      "|    total_time           | 200       |\n",
      "| train/                  |           |\n",
      "|    entropy_loss         | -0.169    |\n",
      "|    intrinsic_loss       | 0.191     |\n",
      "|    policy_gradient_loss | -0.000645 |\n",
      "|    total_loss           | 0.142     |\n",
      "|    value_loss           | 0.191     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 1.58%    |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 119      |\n",
      "|    ep_rew_mean          | -119     |\n",
      "|    num_episodes         | 1237     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 158720   |\n",
      "|    total_time           | 207      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.17    |\n",
      "|    intrinsic_loss       | 0.177    |\n",
      "|    policy_gradient_loss | -0.00234 |\n",
      "|    total_loss           | 0.128    |\n",
      "|    value_loss           | 0.177    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 1.63%    |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 115      |\n",
      "|    ep_rew_mean          | -115     |\n",
      "|    num_episodes         | 1283     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 163840   |\n",
      "|    total_time           | 214      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.114   |\n",
      "|    intrinsic_loss       | 0.182    |\n",
      "|    policy_gradient_loss | -0.00184 |\n",
      "|    total_loss           | 0.134    |\n",
      "|    value_loss           | 0.182    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 1.68%    |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 112      |\n",
      "|    ep_rew_mean          | -112     |\n",
      "|    num_episodes         | 1330     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 168960   |\n",
      "|    total_time           | 222      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.112   |\n",
      "|    intrinsic_loss       | 0.198    |\n",
      "|    policy_gradient_loss | -0.00345 |\n",
      "|    total_loss           | 0.144    |\n",
      "|    value_loss           | 0.198    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 1.74%    |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 111      |\n",
      "|    ep_rew_mean          | -111     |\n",
      "|    num_episodes         | 1376     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 174080   |\n",
      "|    total_time           | 228      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.0802  |\n",
      "|    intrinsic_loss       | 0.182    |\n",
      "|    policy_gradient_loss | -0.00167 |\n",
      "|    total_loss           | 0.134    |\n",
      "|    value_loss           | 0.182    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| Progress                | 1.79%     |\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 113       |\n",
      "|    ep_rew_mean          | -113      |\n",
      "|    num_episodes         | 1421      |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 179200    |\n",
      "|    total_time           | 235       |\n",
      "| train/                  |           |\n",
      "|    entropy_loss         | -0.0796   |\n",
      "|    intrinsic_loss       | 0.183     |\n",
      "|    policy_gradient_loss | -0.000862 |\n",
      "|    total_loss           | 0.138     |\n",
      "|    value_loss           | 0.183     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 1.84%    |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 108      |\n",
      "|    ep_rew_mean          | -108     |\n",
      "|    num_episodes         | 1470     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 184320   |\n",
      "|    total_time           | 242      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.0872  |\n",
      "|    intrinsic_loss       | 0.175    |\n",
      "|    policy_gradient_loss | -0.0011  |\n",
      "|    total_loss           | 0.133    |\n",
      "|    value_loss           | 0.175    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 1.89%    |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 108      |\n",
      "|    ep_rew_mean          | -108     |\n",
      "|    num_episodes         | 1515     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 189440   |\n",
      "|    total_time           | 248      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.0854  |\n",
      "|    intrinsic_loss       | 0.175    |\n",
      "|    policy_gradient_loss | -0.00049 |\n",
      "|    total_loss           | 0.131    |\n",
      "|    value_loss           | 0.175    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| Progress                | 1.94%    |\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 109      |\n",
      "|    ep_rew_mean          | -109     |\n",
      "|    num_episodes         | 1563     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 194560   |\n",
      "|    total_time           | 256      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.103   |\n",
      "|    intrinsic_loss       | 0.176    |\n",
      "|    policy_gradient_loss | -0.00498 |\n",
      "|    total_loss           | 0.126    |\n",
      "|    value_loss           | 0.176    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4a21790c6954>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m model = PPO_RND(env = env, lr = 0.0003, nstep = 128, batch_size = 128, max_grad_norm = 1, \n\u001b[0;32m      2\u001b[0m                 hidden_size = 32, rnd_hidden_size = 32)\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e+7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\MSc Data Analytics\\Reinforcement Learning\\PPO\\ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, log_interval, n_eval_episodes)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrollout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_rnd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrollout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\MSc Data Analytics\\Reinforcement Learning\\PPO\\ppo.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, rollout)\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0madvantages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mext_advantages\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mint_advantages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m                 \u001b[0madvantages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0madvantages\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0madvantages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0madvantages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m                 \u001b[0mratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_log_probs\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mold_log_probs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = PPO_RND(env = env, lr = 0.0003, nstep = 128, batch_size = 128, max_grad_norm = 1, \n",
    "                hidden_size = 32, rnd_hidden_size = 32)\n",
    "model.learn(total_timesteps = 1e+7, log_interval = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(env = env, lr = 0.0003, nstep = 128, batch_size = 128, max_grad_norm = 1, \n",
    "                hidden_size = 32)\n",
    "model.learn(total_timesteps = 1e+7, log_interval = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
