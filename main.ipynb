{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from models import *\n",
    "from ppo import PPO, PPO_RND, PPO_ICM\n",
    "from buffer import RolloutStorage\n",
    "from env import *\n",
    "\n",
    "import torch\n",
    "import torch.distributions as distributions\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "from stable_baselines3.common.cmd_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import vec_normalize, SubprocVecEnv\n",
    "import pybulletgym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO_ICM(env = env, lr = 0.0005, icm_lr = 0.0005, nstep = 32, batch_size = 32, max_grad_norm = 1, \n",
    "                hidden_size = 32, icm_hidden_size = 32, int_vf_coef = 1, vf_coef = 1, n_epochs = 4)\n",
    "model.learn(total_timesteps = 1e+7, log_interval = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs\\PPO\\LunarLander-v2\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -174     |\n",
      "|    num_episodes         | 45       |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 5120     |\n",
      "|    total_time           | 5.15     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.26    |\n",
      "|    policy_gradient_loss | -0.0188  |\n",
      "|    total_loss           | 0.118    |\n",
      "|    value_loss           | 0.149    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -113     |\n",
      "|    num_episodes         | 95       |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 10240    |\n",
      "|    total_time           | 9.99     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.13    |\n",
      "|    policy_gradient_loss | -0.00929 |\n",
      "|    total_loss           | 0.0698   |\n",
      "|    value_loss           | 0.0904   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -54.4    |\n",
      "|    num_episodes         | 133      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 15360    |\n",
      "|    total_time           | 14.7     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -1.1     |\n",
      "|    policy_gradient_loss | -0.00592 |\n",
      "|    total_loss           | 0.0505   |\n",
      "|    value_loss           | 0.0675   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -35.7    |\n",
      "|    num_episodes         | 148      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 20480    |\n",
      "|    total_time           | 20.2     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.985   |\n",
      "|    policy_gradient_loss | -0.0101  |\n",
      "|    total_loss           | -0.00219 |\n",
      "|    value_loss           | 0.0178   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -18      |\n",
      "|    num_episodes         | 164      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 25600    |\n",
      "|    total_time           | 25.9     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.956   |\n",
      "|    policy_gradient_loss | -0.0113  |\n",
      "|    total_loss           | 0.0149   |\n",
      "|    value_loss           | 0.0358   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -12.8    |\n",
      "|    num_episodes         | 182      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 30720    |\n",
      "|    total_time           | 31.8     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.928   |\n",
      "|    policy_gradient_loss | -0.00435 |\n",
      "|    total_loss           | -0.00769 |\n",
      "|    value_loss           | 0.00595  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | -8.53    |\n",
      "|    num_episodes         | 198      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 35840    |\n",
      "|    total_time           | 37.6     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.712   |\n",
      "|    policy_gradient_loss | -0.0102  |\n",
      "|    total_loss           | 0.0109   |\n",
      "|    value_loss           | 0.0282   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 0.297    |\n",
      "|    num_episodes         | 206      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 40960    |\n",
      "|    total_time           | 43.4     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.773   |\n",
      "|    policy_gradient_loss | -0.0113  |\n",
      "|    total_loss           | 0.00846  |\n",
      "|    value_loss           | 0.0275   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 17.3     |\n",
      "|    num_episodes         | 218      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 46080    |\n",
      "|    total_time           | 49.1     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.78    |\n",
      "|    policy_gradient_loss | -0.00488 |\n",
      "|    total_loss           | 0.0216   |\n",
      "|    value_loss           | 0.0342   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 28.5     |\n",
      "|    num_episodes         | 226      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 51200    |\n",
      "|    total_time           | 55       |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.847   |\n",
      "|    policy_gradient_loss | -0.0126  |\n",
      "|    total_loss           | 0.0209   |\n",
      "|    value_loss           | 0.042    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 36.9     |\n",
      "|    num_episodes         | 235      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 56320    |\n",
      "|    total_time           | 60.7     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.732   |\n",
      "|    policy_gradient_loss | -0.0133  |\n",
      "|    total_loss           | 0.000428 |\n",
      "|    value_loss           | 0.0211   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 46.9     |\n",
      "|    num_episodes         | 249      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 61440    |\n",
      "|    total_time           | 66.4     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.768   |\n",
      "|    policy_gradient_loss | -0.0124  |\n",
      "|    total_loss           | 0.00634  |\n",
      "|    value_loss           | 0.0264   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 52.4     |\n",
      "|    num_episodes         | 263      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 66560    |\n",
      "|    total_time           | 72.2     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.755   |\n",
      "|    policy_gradient_loss | -0.00465 |\n",
      "|    total_loss           | 0.0944   |\n",
      "|    value_loss           | 0.107    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 74.9     |\n",
      "|    num_episodes         | 276      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 71680    |\n",
      "|    total_time           | 77.5     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.746   |\n",
      "|    policy_gradient_loss | -0.00941 |\n",
      "|    total_loss           | 0.044    |\n",
      "|    value_loss           | 0.0609   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 87.1     |\n",
      "|    num_episodes         | 290      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 76800    |\n",
      "|    total_time           | 82.8     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.756   |\n",
      "|    policy_gradient_loss | -0.00576 |\n",
      "|    total_loss           | 0.00653  |\n",
      "|    value_loss           | 0.0199   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 94.5     |\n",
      "|    num_episodes         | 303      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 81920    |\n",
      "|    total_time           | 88.8     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.642   |\n",
      "|    policy_gradient_loss | -0.00439 |\n",
      "|    total_loss           | 0.000353 |\n",
      "|    value_loss           | 0.0112   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 97.5     |\n",
      "|    num_episodes         | 319      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 87040    |\n",
      "|    total_time           | 94.4     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.733   |\n",
      "|    policy_gradient_loss | -0.00446 |\n",
      "|    total_loss           | -0.00707 |\n",
      "|    value_loss           | 0.00472  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 106      |\n",
      "|    num_episodes         | 327      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 92160    |\n",
      "|    total_time           | 99.8     |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.586   |\n",
      "|    policy_gradient_loss | -0.00474 |\n",
      "|    total_loss           | -0.00862 |\n",
      "|    value_loss           | 0.00199  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 110      |\n",
      "|    num_episodes         | 337      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 97280    |\n",
      "|    total_time           | 106      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.693   |\n",
      "|    policy_gradient_loss | -0.00581 |\n",
      "|    total_loss           | 0.0599   |\n",
      "|    value_loss           | 0.0727   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 118      |\n",
      "|    num_episodes         | 352      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 102400   |\n",
      "|    total_time           | 112      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.77    |\n",
      "|    policy_gradient_loss | -0.00682 |\n",
      "|    total_loss           | 0.065    |\n",
      "|    value_loss           | 0.0795   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 114      |\n",
      "|    num_episodes         | 360      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 107520   |\n",
      "|    total_time           | 118      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.696   |\n",
      "|    policy_gradient_loss | -0.00513 |\n",
      "|    total_loss           | 0.000857 |\n",
      "|    value_loss           | 0.0129   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 106      |\n",
      "|    num_episodes         | 369      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 112640   |\n",
      "|    total_time           | 124      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.579   |\n",
      "|    policy_gradient_loss | -0.001   |\n",
      "|    total_loss           | -0.00254 |\n",
      "|    value_loss           | 0.00425  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 113      |\n",
      "|    num_episodes         | 379      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 117760   |\n",
      "|    total_time           | 131      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.71    |\n",
      "|    policy_gradient_loss | -0.00528 |\n",
      "|    total_loss           | 0.0416   |\n",
      "|    value_loss           | 0.0539   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 110      |\n",
      "|    num_episodes         | 392      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 122880   |\n",
      "|    total_time           | 137      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.611   |\n",
      "|    policy_gradient_loss | 0.00117  |\n",
      "|    total_loss           | 0.0887   |\n",
      "|    value_loss           | 0.0936   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 113      |\n",
      "|    num_episodes         | 401      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 128000   |\n",
      "|    total_time           | 143      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.585   |\n",
      "|    policy_gradient_loss | 5.98e-05 |\n",
      "|    total_loss           | 0.142    |\n",
      "|    value_loss           | 0.148    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 109      |\n",
      "|    num_episodes         | 413      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 133120   |\n",
      "|    total_time           | 148      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.724   |\n",
      "|    policy_gradient_loss | -0.0025  |\n",
      "|    total_loss           | 0.195    |\n",
      "|    value_loss           | 0.205    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 97.8     |\n",
      "|    num_episodes         | 424      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 138240   |\n",
      "|    total_time           | 155      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.714   |\n",
      "|    policy_gradient_loss | -0.00916 |\n",
      "|    total_loss           | -0.0063  |\n",
      "|    value_loss           | 0.01     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 99.4     |\n",
      "|    num_episodes         | 435      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 143360   |\n",
      "|    total_time           | 160      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.757   |\n",
      "|    policy_gradient_loss | -0.00731 |\n",
      "|    total_loss           | -0.00195 |\n",
      "|    value_loss           | 0.0129   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 100      |\n",
      "|    num_episodes         | 449      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 148480   |\n",
      "|    total_time           | 166      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.51    |\n",
      "|    policy_gradient_loss | -0.00278 |\n",
      "|    total_loss           | 0.0857   |\n",
      "|    value_loss           | 0.0936   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 106      |\n",
      "|    num_episodes         | 459      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 153600   |\n",
      "|    total_time           | 173      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.647   |\n",
      "|    policy_gradient_loss | 0.000592 |\n",
      "|    total_loss           | 0.0221   |\n",
      "|    value_loss           | 0.0279   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 106      |\n",
      "|    num_episodes         | 473      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 158720   |\n",
      "|    total_time           | 178      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.655   |\n",
      "|    policy_gradient_loss | -0.00271 |\n",
      "|    total_loss           | -0.00196 |\n",
      "|    value_loss           | 0.00731  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 115      |\n",
      "|    num_episodes         | 484      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 163840   |\n",
      "|    total_time           | 185      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.446   |\n",
      "|    policy_gradient_loss | -0.00608 |\n",
      "|    total_loss           | 0.0137   |\n",
      "|    value_loss           | 0.0243   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 116      |\n",
      "|    num_episodes         | 496      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 168960   |\n",
      "|    total_time           | 191      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.75    |\n",
      "|    policy_gradient_loss | -0.00498 |\n",
      "|    total_loss           | 0.0195   |\n",
      "|    value_loss           | 0.032    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 114      |\n",
      "|    num_episodes         | 507      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 174080   |\n",
      "|    total_time           | 196      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.809   |\n",
      "|    policy_gradient_loss | -0.0049  |\n",
      "|    total_loss           | 0.00693  |\n",
      "|    value_loss           | 0.0199   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 123      |\n",
      "|    num_episodes         | 519      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 179200   |\n",
      "|    total_time           | 202      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.635   |\n",
      "|    policy_gradient_loss | -0.00646 |\n",
      "|    total_loss           | -0.00157 |\n",
      "|    value_loss           | 0.0112   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 125      |\n",
      "|    num_episodes         | 531      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 184320   |\n",
      "|    total_time           | 208      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.712   |\n",
      "|    policy_gradient_loss | -0.00229 |\n",
      "|    total_loss           | -0.00593 |\n",
      "|    value_loss           | 0.00348  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 125      |\n",
      "|    num_episodes         | 542      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 189440   |\n",
      "|    total_time           | 214      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.559   |\n",
      "|    policy_gradient_loss | -0.00384 |\n",
      "|    total_loss           | 0.206    |\n",
      "|    value_loss           | 0.215    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 124      |\n",
      "|    num_episodes         | 555      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 194560   |\n",
      "|    total_time           | 221      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.692   |\n",
      "|    policy_gradient_loss | -0.0102  |\n",
      "|    total_loss           | -0.00749 |\n",
      "|    value_loss           | 0.00961  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 133      |\n",
      "|    num_episodes         | 570      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 199680   |\n",
      "|    total_time           | 226      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.565   |\n",
      "|    policy_gradient_loss | -0.0119  |\n",
      "|    total_loss           | 0.0279   |\n",
      "|    value_loss           | 0.0454   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 130      |\n",
      "|    num_episodes         | 585      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 204800   |\n",
      "|    total_time           | 232      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.611   |\n",
      "|    policy_gradient_loss | -0.00338 |\n",
      "|    total_loss           | 0.151    |\n",
      "|    value_loss           | 0.161    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 133      |\n",
      "|    num_episodes         | 599      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 209920   |\n",
      "|    total_time           | 238      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.525   |\n",
      "|    policy_gradient_loss | -0.0134  |\n",
      "|    total_loss           | 0.00475  |\n",
      "|    value_loss           | 0.0234   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 134      |\n",
      "|    num_episodes         | 614      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 215040   |\n",
      "|    total_time           | 243      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.604   |\n",
      "|    policy_gradient_loss | -0.00185 |\n",
      "|    total_loss           | 0.159    |\n",
      "|    value_loss           | 0.167    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 139      |\n",
      "|    num_episodes         | 625      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 220160   |\n",
      "|    total_time           | 249      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.764   |\n",
      "|    policy_gradient_loss | -0.00404 |\n",
      "|    total_loss           | 0.0132   |\n",
      "|    value_loss           | 0.0249   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 148      |\n",
      "|    num_episodes         | 639      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 225280   |\n",
      "|    total_time           | 255      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.521   |\n",
      "|    policy_gradient_loss | -0.00188 |\n",
      "|    total_loss           | 0.167    |\n",
      "|    value_loss           | 0.174    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 147      |\n",
      "|    num_episodes         | 648      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 230400   |\n",
      "|    total_time           | 261      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.586   |\n",
      "|    policy_gradient_loss | -0.00596 |\n",
      "|    total_loss           | 0.0626   |\n",
      "|    value_loss           | 0.0744   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 143      |\n",
      "|    num_episodes         | 664      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 235520   |\n",
      "|    total_time           | 268      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.771   |\n",
      "|    policy_gradient_loss | -0.0149  |\n",
      "|    total_loss           | 0.015    |\n",
      "|    value_loss           | 0.0377   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 141      |\n",
      "|    num_episodes         | 678      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 240640   |\n",
      "|    total_time           | 273      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.71    |\n",
      "|    policy_gradient_loss | -0.00629 |\n",
      "|    total_loss           | 0.00826  |\n",
      "|    value_loss           | 0.0216   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_rew_mean          | 138       |\n",
      "|    num_episodes         | 688       |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 245760    |\n",
      "|    total_time           | 279       |\n",
      "| train/                  |           |\n",
      "|    entropy_loss         | -0.742    |\n",
      "|    policy_gradient_loss | -0.000661 |\n",
      "|    total_loss           | 0.0288    |\n",
      "|    value_loss           | 0.0368    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 134      |\n",
      "|    num_episodes         | 706      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 250880   |\n",
      "|    total_time           | 285      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.654   |\n",
      "|    policy_gradient_loss | -0.00553 |\n",
      "|    total_loss           | 0.0565   |\n",
      "|    value_loss           | 0.0685   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 125      |\n",
      "|    num_episodes         | 721      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 256000   |\n",
      "|    total_time           | 290      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.702   |\n",
      "|    policy_gradient_loss | -0.0025  |\n",
      "|    total_loss           | 0.0595   |\n",
      "|    value_loss           | 0.069    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 116      |\n",
      "|    num_episodes         | 737      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 261120   |\n",
      "|    total_time           | 296      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.541   |\n",
      "|    policy_gradient_loss | -0.0108  |\n",
      "|    total_loss           | 0.124    |\n",
      "|    value_loss           | 0.141    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_rew_mean          | 108       |\n",
      "|    num_episodes         | 760       |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 266240    |\n",
      "|    total_time           | 302       |\n",
      "| train/                  |           |\n",
      "|    entropy_loss         | -0.646    |\n",
      "|    policy_gradient_loss | -1.76e-05 |\n",
      "|    total_loss           | 0.066     |\n",
      "|    value_loss           | 0.0725    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 111      |\n",
      "|    num_episodes         | 772      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 271360   |\n",
      "|    total_time           | 307      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.592   |\n",
      "|    policy_gradient_loss | -0.013   |\n",
      "|    total_loss           | 0.0542   |\n",
      "|    value_loss           | 0.0731   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 105      |\n",
      "|    num_episodes         | 785      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 276480   |\n",
      "|    total_time           | 313      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.615   |\n",
      "|    policy_gradient_loss | -0.00279 |\n",
      "|    total_loss           | 0.0592   |\n",
      "|    value_loss           | 0.0682   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 112      |\n",
      "|    num_episodes         | 791      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 281600   |\n",
      "|    total_time           | 319      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.586   |\n",
      "|    policy_gradient_loss | -0.00636 |\n",
      "|    total_loss           | 0.0563   |\n",
      "|    value_loss           | 0.0685   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 113      |\n",
      "|    num_episodes         | 803      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 286720   |\n",
      "|    total_time           | 324      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.592   |\n",
      "|    policy_gradient_loss | -0.00961 |\n",
      "|    total_loss           | 0.138    |\n",
      "|    value_loss           | 0.154    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 111      |\n",
      "|    num_episodes         | 816      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 291840   |\n",
      "|    total_time           | 330      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.703   |\n",
      "|    policy_gradient_loss | -0.0054  |\n",
      "|    total_loss           | -0.0108  |\n",
      "|    value_loss           | 0.00167  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 116      |\n",
      "|    num_episodes         | 823      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 296960   |\n",
      "|    total_time           | 336      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.7     |\n",
      "|    policy_gradient_loss | -0.00614 |\n",
      "|    total_loss           | -0.01    |\n",
      "|    value_loss           | 0.0031   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 105      |\n",
      "|    num_episodes         | 839      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 302080   |\n",
      "|    total_time           | 342      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.569   |\n",
      "|    policy_gradient_loss | 0.000466 |\n",
      "|    total_loss           | 0.00988  |\n",
      "|    value_loss           | 0.0151   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 109      |\n",
      "|    num_episodes         | 847      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 307200   |\n",
      "|    total_time           | 348      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.535   |\n",
      "|    policy_gradient_loss | -0.00681 |\n",
      "|    total_loss           | 0.101    |\n",
      "|    value_loss           | 0.113    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 123      |\n",
      "|    num_episodes         | 862      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 312320   |\n",
      "|    total_time           | 354      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.63    |\n",
      "|    policy_gradient_loss | -0.00448 |\n",
      "|    total_loss           | 0.0692   |\n",
      "|    value_loss           | 0.08     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 122      |\n",
      "|    num_episodes         | 876      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 317440   |\n",
      "|    total_time           | 360      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.66    |\n",
      "|    policy_gradient_loss | -0.00354 |\n",
      "|    total_loss           | 0.00835  |\n",
      "|    value_loss           | 0.0185   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 123      |\n",
      "|    num_episodes         | 891      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 322560   |\n",
      "|    total_time           | 366      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.554   |\n",
      "|    policy_gradient_loss | -0.00915 |\n",
      "|    total_loss           | -0.0122  |\n",
      "|    value_loss           | 0.00246  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 123      |\n",
      "|    num_episodes         | 898      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 327680   |\n",
      "|    total_time           | 371      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.578   |\n",
      "|    policy_gradient_loss | 0.00171  |\n",
      "|    total_loss           | -0.00119 |\n",
      "|    value_loss           | 0.00288  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 139      |\n",
      "|    num_episodes         | 912      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 332800   |\n",
      "|    total_time           | 378      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.593   |\n",
      "|    policy_gradient_loss | -0.0057  |\n",
      "|    total_loss           | 0.174    |\n",
      "|    value_loss           | 0.185    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 141      |\n",
      "|    num_episodes         | 921      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 337920   |\n",
      "|    total_time           | 383      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.582   |\n",
      "|    policy_gradient_loss | -0.00656 |\n",
      "|    total_loss           | 0.0979   |\n",
      "|    value_loss           | 0.11     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 150      |\n",
      "|    num_episodes         | 928      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 343040   |\n",
      "|    total_time           | 389      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.541   |\n",
      "|    policy_gradient_loss | -0.00413 |\n",
      "|    total_loss           | 0.00128  |\n",
      "|    value_loss           | 0.0108   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 152      |\n",
      "|    num_episodes         | 939      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 348160   |\n",
      "|    total_time           | 396      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.601   |\n",
      "|    policy_gradient_loss | -0.0143  |\n",
      "|    total_loss           | 0.0506   |\n",
      "|    value_loss           | 0.0709   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 145      |\n",
      "|    num_episodes         | 951      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 353280   |\n",
      "|    total_time           | 402      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.626   |\n",
      "|    policy_gradient_loss | -0.00157 |\n",
      "|    total_loss           | 0.0144   |\n",
      "|    value_loss           | 0.0222   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 140      |\n",
      "|    num_episodes         | 964      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 358400   |\n",
      "|    total_time           | 408      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.5     |\n",
      "|    policy_gradient_loss | -0.00434 |\n",
      "|    total_loss           | 0.161    |\n",
      "|    value_loss           | 0.171    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 145      |\n",
      "|    num_episodes         | 978      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 363520   |\n",
      "|    total_time           | 415      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.618   |\n",
      "|    policy_gradient_loss | -0.00416 |\n",
      "|    total_loss           | 0.00351  |\n",
      "|    value_loss           | 0.0139   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 143      |\n",
      "|    num_episodes         | 988      |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 368640   |\n",
      "|    total_time           | 421      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.538   |\n",
      "|    policy_gradient_loss | -0.00417 |\n",
      "|    total_loss           | -0.00804 |\n",
      "|    value_loss           | 0.00152  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 149      |\n",
      "|    num_episodes         | 1002     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 373760   |\n",
      "|    total_time           | 429      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.498   |\n",
      "|    policy_gradient_loss | -0.00627 |\n",
      "|    total_loss           | 0.139    |\n",
      "|    value_loss           | 0.15     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 141      |\n",
      "|    num_episodes         | 1021     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 378880   |\n",
      "|    total_time           | 434      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.562   |\n",
      "|    policy_gradient_loss | 0.00156  |\n",
      "|    total_loss           | 0.169    |\n",
      "|    value_loss           | 0.173    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 135      |\n",
      "|    num_episodes         | 1035     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 384000   |\n",
      "|    total_time           | 440      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.611   |\n",
      "|    policy_gradient_loss | -0.00932 |\n",
      "|    total_loss           | -0.0076  |\n",
      "|    value_loss           | 0.00783  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 146      |\n",
      "|    num_episodes         | 1049     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 389120   |\n",
      "|    total_time           | 446      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.592   |\n",
      "|    policy_gradient_loss | 0.00398  |\n",
      "|    total_loss           | 0.00997  |\n",
      "|    value_loss           | 0.0119   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 148      |\n",
      "|    num_episodes         | 1064     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 394240   |\n",
      "|    total_time           | 452      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.639   |\n",
      "|    policy_gradient_loss | 0.000852 |\n",
      "|    total_loss           | 0.0374   |\n",
      "|    value_loss           | 0.043    |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_rew_mean          | 158       |\n",
      "|    num_episodes         | 1081      |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 399360    |\n",
      "|    total_time           | 458       |\n",
      "| train/                  |           |\n",
      "|    entropy_loss         | -0.439    |\n",
      "|    policy_gradient_loss | -0.000812 |\n",
      "|    total_loss           | 0.197     |\n",
      "|    value_loss           | 0.202     |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 166      |\n",
      "|    num_episodes         | 1091     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 404480   |\n",
      "|    total_time           | 464      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.562   |\n",
      "|    policy_gradient_loss | -0.0106  |\n",
      "|    total_loss           | -0.0147  |\n",
      "|    value_loss           | 0.00151  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 161      |\n",
      "|    num_episodes         | 1101     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 409600   |\n",
      "|    total_time           | 470      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.636   |\n",
      "|    policy_gradient_loss | -0.00312 |\n",
      "|    total_loss           | 0.0129   |\n",
      "|    value_loss           | 0.0224   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 168      |\n",
      "|    num_episodes         | 1107     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 414720   |\n",
      "|    total_time           | 477      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.715   |\n",
      "|    policy_gradient_loss | -0.0047  |\n",
      "|    total_loss           | -0.00987 |\n",
      "|    value_loss           | 0.00198  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 172      |\n",
      "|    num_episodes         | 1123     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 419840   |\n",
      "|    total_time           | 482      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.626   |\n",
      "|    policy_gradient_loss | -0.00283 |\n",
      "|    total_loss           | 0.0125   |\n",
      "|    value_loss           | 0.0216   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 173      |\n",
      "|    num_episodes         | 1129     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 424960   |\n",
      "|    total_time           | 488      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.606   |\n",
      "|    policy_gradient_loss | -0.00484 |\n",
      "|    total_loss           | -0.00844 |\n",
      "|    value_loss           | 0.00245  |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 169      |\n",
      "|    num_episodes         | 1143     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 430080   |\n",
      "|    total_time           | 494      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.607   |\n",
      "|    policy_gradient_loss | -0.0047  |\n",
      "|    total_loss           | 0.0558   |\n",
      "|    value_loss           | 0.0666   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 174      |\n",
      "|    num_episodes         | 1163     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 435200   |\n",
      "|    total_time           | 500      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.432   |\n",
      "|    policy_gradient_loss | 1.02e-07 |\n",
      "|    total_loss           | 0.123    |\n",
      "|    value_loss           | 0.127    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 167      |\n",
      "|    num_episodes         | 1174     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 440320   |\n",
      "|    total_time           | 506      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.645   |\n",
      "|    policy_gradient_loss | -0.00368 |\n",
      "|    total_loss           | -0.00905 |\n",
      "|    value_loss           | 0.00108  |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_rew_mean          | 162       |\n",
      "|    num_episodes         | 1182      |\n",
      "| time/                   |           |\n",
      "|    total timesteps      | 445440    |\n",
      "|    total_time           | 513       |\n",
      "| train/                  |           |\n",
      "|    entropy_loss         | -0.683    |\n",
      "|    policy_gradient_loss | -0.000855 |\n",
      "|    total_loss           | 0.0795    |\n",
      "|    value_loss           | 0.0872    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 162      |\n",
      "|    num_episodes         | 1192     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 450560   |\n",
      "|    total_time           | 518      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.78    |\n",
      "|    policy_gradient_loss | 0.00192  |\n",
      "|    total_loss           | 0.0693   |\n",
      "|    value_loss           | 0.0752   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 167      |\n",
      "|    num_episodes         | 1199     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 455680   |\n",
      "|    total_time           | 525      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.661   |\n",
      "|    policy_gradient_loss | -0.00191 |\n",
      "|    total_loss           | 0.019    |\n",
      "|    value_loss           | 0.0275   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 154      |\n",
      "|    num_episodes         | 1217     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 460800   |\n",
      "|    total_time           | 530      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.585   |\n",
      "|    policy_gradient_loss | -0.00416 |\n",
      "|    total_loss           | 0.0145   |\n",
      "|    value_loss           | 0.0245   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 164      |\n",
      "|    num_episodes         | 1224     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 465920   |\n",
      "|    total_time           | 537      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.552   |\n",
      "|    policy_gradient_loss | 0.00154  |\n",
      "|    total_loss           | 0.0718   |\n",
      "|    value_loss           | 0.0758   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_rew_mean          | 166      |\n",
      "|    num_episodes         | 1232     |\n",
      "| time/                   |          |\n",
      "|    total timesteps      | 471040   |\n",
      "|    total_time           | 543      |\n",
      "| train/                  |          |\n",
      "|    entropy_loss         | -0.656   |\n",
      "|    policy_gradient_loss | -0.00325 |\n",
      "|    total_loss           | -0.00744 |\n",
      "|    value_loss           | 0.00237  |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ktiju\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-2-01629d45bfb2>\", line 2, in <module>\n",
      "    model.learn(total_timesteps = 1e+7, log_interval = 10)\n",
      "  File \"C:\\Users\\ktiju\\Documents\\MSc Data Analytics\\Reinforcement Learning\\PPO\\ppo.py\", line 216, in learn\n",
      "    self.train()\n",
      "  File \"C:\\Users\\ktiju\\Documents\\MSc Data Analytics\\Reinforcement Learning\\PPO\\ppo.py\", line 181, in train\n",
      "    loss.backward()\n",
      "  File \"C:\\Users\\ktiju\\anaconda3\\lib\\site-packages\\torch\\tensor.py\", line 198, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"C:\\Users\\ktiju\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\", line 100, in backward\n",
      "    allow_unreachable=True)  # allow_unreachable flag\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ktiju\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ktiju\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\ktiju\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\ktiju\\anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\ktiju\\anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\ktiju\\anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\ktiju\\anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\ktiju\\anaconda3\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\ktiju\\anaconda3\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\ktiju\\anaconda3\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\ktiju\\anaconda3\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "model = PPO(env_id = \"LunarLander-v2\", lr = 0.0003, nstep = 64, batch_size = 32, hidden_size = 64, n_epochs = 4)\n",
    "model.learn(total_timesteps = 1e+7, log_interval = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO_RND(env = env, lr = 0.003, nstep = 64, batch_size = 32, max_grad_norm = 1, \n",
    "                hidden_size = 64, rnd_hidden_size = 32, n_epochs = 4, vf_coef = 1, rnd_start = 1e+4)\n",
    "model.learn(total_timesteps = 1e+7, log_interval = 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
